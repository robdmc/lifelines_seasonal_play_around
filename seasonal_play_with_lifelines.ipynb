{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines.fitters import ParametericUnivariateFitter\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from autograd import numpy as np\n",
    "from autograd import grad\n",
    "from scipy.stats import expon, bernoulli\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import itertools\n",
    "import sys\n",
    "from autograd import numpy as anp\n",
    "from autograd import value_and_grad, grad\n",
    "from autograd import elementwise_grad as egrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the previously saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>duration</th>\n",
       "      <th>event_occured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  duration  event_occured\n",
       "0 2019-04-18         0              1\n",
       "1 2021-06-22        99              1"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./seasonal_1000a.csv', parse_dates=['date'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Interval('2019-01-03', '2019-01-07', closed='both'),\n",
       " Interval('2019-01-03', '2019-04-07', closed='both'),\n",
       " Interval('2019-01-04', '2019-01-10', closed='both')]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_life_intervals(duration, date):\n",
    "    \"\"\"\n",
    "    This takes durations and dates.  It returns pandas intervals\n",
    "    representing the interval over which each record lives\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        'duration': list(duration),\n",
    "        'end_date': list(date)\n",
    "    })\n",
    "    df['start_date'] = df.end_date - df.duration * pd.Timedelta(days=1)\n",
    "    df['live_interval'] = [\n",
    "        pd.Interval(start, end, closed='both') \n",
    "        for (start, end) in zip(df.start_date, df.end_date)\n",
    "    ]\n",
    "    return sorted(df.live_interval)\n",
    "\n",
    "life_intervals = get_life_intervals(df.duration, df.date)\n",
    "life_intervals[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Interval('2019-01-01', '2019-04-01', closed='left'),\n",
       " Interval('2019-04-01', '2019-07-01', closed='left'),\n",
       " Interval('2019-07-01', '2019-10-01', closed='left')]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_bin_intervals(duration, date, offset):\n",
    "    \"\"\"\n",
    "    Takes durations dates, and a pandas time offset.\n",
    "    Returns intervals of offset covering the whole dataset\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        'duration': list(duration),\n",
    "        'end_date': list(date)\n",
    "    })\n",
    "    df['start_date'] = df.end_date - df.duration * pd.Timedelta(days=1)\n",
    "    \n",
    "    min_date = df.start_date.min()\n",
    "    max_date = df.end_date.max()\n",
    "    \n",
    "    min_bin_time = offset.rollback(min_date)\n",
    "    max_bin_time = offset.rollforward(max_date)\n",
    "    bin_dates = list(pd.date_range(min_bin_time, max_bin_time))\n",
    "    ind = pd.interval_range(start=min_bin_time, end=max_bin_time, freq=offset, closed='left')\n",
    "    return sorted(ind)\n",
    "\n",
    "bin_intervals = get_bin_intervals(df.duration, df.date, pd.offsets.QuarterBegin(startingMonth=1))\n",
    "bin_intervals[: 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'row_index': 986, 'col_index': 0, 'duration': 399.0, 'tau_bin_start': -60.0, 'tau_bin_end': 32.0, 'lower_lim': 0.0, 'upper_lim': 32.0}\n",
      "{'row_index': 986, 'col_index': 1, 'duration': 399.0, 'tau_bin_start': 32.0, 'tau_bin_end': 122.0, 'lower_lim': 32.0, 'upper_lim': 122.0}\n",
      "{'row_index': 986, 'col_index': 2, 'duration': 399.0, 'tau_bin_start': 122.0, 'tau_bin_end': 213.0, 'lower_lim': 122.0, 'upper_lim': 213.0}\n",
      "{'row_index': 986, 'col_index': 3, 'duration': 399.0, 'tau_bin_start': 213.0, 'tau_bin_end': 305.0, 'lower_lim': 213.0, 'upper_lim': 305.0}\n",
      "{'row_index': 986, 'col_index': 4, 'duration': 399.0, 'tau_bin_start': 305.0, 'tau_bin_end': 397.0, 'lower_lim': 305.0, 'upper_lim': 397.0}\n",
      "{'row_index': 986, 'col_index': 5, 'duration': 399.0, 'tau_bin_start': 397.0, 'tau_bin_end': 487.0, 'lower_lim': 397.0, 'upper_lim': 399.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_index</th>\n",
       "      <th>duration</th>\n",
       "      <th>lower_lim</th>\n",
       "      <th>row_index</th>\n",
       "      <th>tau_bin_end</th>\n",
       "      <th>tau_bin_start</th>\n",
       "      <th>upper_lim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1</td>\n",
       "      <td>179.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_index  duration  lower_lim  row_index  tau_bin_end  tau_bin_start  \\\n",
       "0          0       4.0        0.0          0         88.0           -2.0   \n",
       "1          0      94.0        0.0          1         88.0           -2.0   \n",
       "2          1      94.0       88.0          1        179.0           88.0   \n",
       "3          0       6.0        0.0          2         87.0           -3.0   \n",
       "4          0      71.0        0.0          3         83.0           -7.0   \n",
       "\n",
       "   upper_lim  \n",
       "0        4.0  \n",
       "1       88.0  \n",
       "2       94.0  \n",
       "3        6.0  \n",
       "4       71.0  "
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_record(life_interval, bin_interval, row_index, col_index, time_step):\n",
    "    \"\"\"\n",
    "    Computes the values needed for feeding into cumulative hazard functions\n",
    "    \"\"\"\n",
    "    life_start, life_end = life_interval.left, life_interval.right\n",
    "    bin_start, bin_end = bin_interval.left, bin_interval.right\n",
    "    \n",
    "    tau_bin_start = (bin_start - life_start) / time_step\n",
    "    tau_bin_end = (bin_end - life_start) / time_step\n",
    "    duration = life_interval.length / time_step\n",
    "    \n",
    "    \n",
    "    lower_lim = np.maximum(0, tau_bin_start)\n",
    "    upper_lim = np.minimum(duration, tau_bin_end)\n",
    "    \n",
    "    rec =  {\n",
    "        'row_index': row_index,\n",
    "        'col_index': col_index,\n",
    "        'duration': duration,\n",
    "        'tau_bin_start': tau_bin_start,\n",
    "        'tau_bin_end': tau_bin_end,\n",
    "        'lower_lim': lower_lim,\n",
    "        'upper_lim': upper_lim\n",
    "    }\n",
    "\n",
    "    if duration == 399:\n",
    "        print(rec)\n",
    "        \n",
    "    return rec\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "rec_list = []\n",
    "\n",
    "for row_index, life_interval in enumerate(life_intervals):\n",
    "    col_index = 0\n",
    "    has_overlapped = False\n",
    "    for bin_interval in bin_intervals:\n",
    "        if life_interval.overlaps(bin_interval):\n",
    "            rec = compute_record(\n",
    "                life_interval, bin_interval, row_index, col_index, time_step=pd.Timedelta(days=1))\n",
    "            rec_list.append(rec)\n",
    "            col_index += 1\n",
    "            has_overlapped = True\n",
    "        else:\n",
    "            if has_overlapped:\n",
    "                break\n",
    "            \n",
    "            \n",
    "dfx = pd.DataFrame(rec_list)\n",
    "dfx.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This populates upper/lower time limits needed for integrating each cumulative contribution\n",
    "\"\"\"\n",
    "num_rows = len(df)\n",
    "num_cols = dfx.col_index.max() + 1\n",
    "lower_lims = anp.zeros(shape=(num_rows, num_cols))\n",
    "upper_lims = anp.zeros(shape=(num_rows, num_cols))\n",
    "\n",
    "for rec in dfx.itertuples():\n",
    "    lower_lims[rec.row_index, rec.col_index] = rec.lower_lim\n",
    "    upper_lims[rec.row_index, rec.col_index] = rec.upper_lim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [88., 94.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 6.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [16., 17.,  0., ...,  0.,  0.,  0.],\n",
       "       [15., 30.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 4., 58.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_lims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def H(t2, t1, w):\n",
    "    \"\"\"\n",
    "    This is the cumulative hazard function (exponential for now)\n",
    "    \"\"\"\n",
    "    h_base = t2 - t1\n",
    "    w = anp.array(w).reshape(len(w), 1)\n",
    "    return h_base @ w\n",
    "\n",
    "\n",
    "w = np.array([1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=np.float64)\n",
    "# H(upper_lims, lower_lims, w)\n",
    "h = egrad(H, argnum=0)\n",
    "h(upper_lims, lower_lims, w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(t1, t2, w):\n",
    "    M = anp.matrix(t2 - t1)\n",
    "    w = anp.array(w)\n",
    "    w = anp.matrix(w.reshape(len(w), 1))\n",
    "    v = M * w\n",
    "    v = np.array(v).reshape((v.shape[0] * v.shape[1],))\n",
    "    print(v.shape)\n",
    "    print('max', v.max())\n",
    "#     return(v)\n",
    "    return np.sum(v)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5., 11.])"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = anp.array([[1, 2], [3, 4]], dtype=np.float64)\n",
    "w = anp.array([[1], [2]], dtype=np.float64)\n",
    "np.array(np.matrix(M) * np.matrix(w)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.],\n",
       "       [6.]])"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(M, w):\n",
    "    return M @ w\n",
    "    return np.array(np.matrix(M) * np.matrix(w)).flatten()\n",
    "\n",
    "g = egrad(f, argnum=1)\n",
    "g(M, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [6., 8.]])"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.],\n",
       "       [11.]])"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M@w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
